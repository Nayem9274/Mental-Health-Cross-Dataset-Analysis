{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Dolv-oqSwUj3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.gridspec import GridSpec\n",
        "from IPython.display import display\n",
        "import seaborn as sns\n",
        "import statsmodels.api as sm\n",
        "import scipy.stats as stats\n",
        "from statsmodels.formula.api import ols\n",
        "from scipy.stats import ttest_ind, chi2_contingency"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "hQOo_8jnykBA"
      },
      "outputs": [],
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "DMSjDc9sylSz"
      },
      "outputs": [],
      "source": [
        "input=pd.read_csv(r'C:\\Users\\User\\Downloads/EEG.machinelearing_data_BRMH.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWKNpr0_4H4P",
        "outputId": "01073ed4-7d50-4b6e-dfad-dd139500e316"
      },
      "outputs": [],
      "source": [
        "# Identify unnamed columns\n",
        "unnamed_columns = [col for col in input.columns if 'Unnamed' in col]\n",
        "if not unnamed_columns:\n",
        "    print(\"No unnamed columns found.\")\n",
        "else:\n",
        "    print(\"Unnamed columns:\", unnamed_columns)\n",
        "    print(\" Dropping it.\")\n",
        "\n",
        "# Check if unnamed columns are empty\n",
        "empty_unnamed_columns = [col for col in unnamed_columns if input[col].isnull().all()]\n",
        "\n",
        "# Drop empty unnamed columns\n",
        "input.drop(empty_unnamed_columns, axis=1, inplace=True)\n",
        "\n",
        "unnamed_columns = [col for col in input.columns if 'Unnamed' in col]\n",
        "if not unnamed_columns:\n",
        "    print(\"No unnamed columns found.\")\n",
        "else:\n",
        "    print(\"Unnamed columns:\", unnamed_columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        },
        "id": "OgACgZA9yx8w",
        "outputId": "05b1fd9b-b0c1-4f4b-90d3-001be6715de0"
      },
      "outputs": [],
      "source": [
        "input.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nWcDWCSWzGG6",
        "outputId": "cac9e333-6724-44e5-dd22-ff88ed5e1d21"
      },
      "outputs": [],
      "source": [
        "input.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7CJu_NEN0g10",
        "outputId": "786e7a95-2c12-4ccb-ed64-8691a40865b2"
      },
      "outputs": [],
      "source": [
        "columns_of_interest = input.columns  # Adjust column indices as needed\n",
        "\n",
        "nan_counts_specific = input[columns_of_interest].isna().sum()\n",
        "nan_counts_specific = nan_counts_specific[nan_counts_specific != 0]\n",
        "\n",
        "if not nan_counts_specific.empty:\n",
        "    print(\"NaN counts for specified columns:\")\n",
        "    print(nan_counts_specific)\n",
        "else:\n",
        "    print(\"No NaN values found in specified columns.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VCTrIjfA048o",
        "outputId": "2bdb9178-03da-46bb-bfda-db3f29043af9"
      },
      "outputs": [],
      "source": [
        "columns_of_interest = ['sex','education','IQ','main.disorder','specific.disorder']\n",
        "# Count unique values in specified columns\n",
        "unique_value_counts = input[columns_of_interest].nunique()\n",
        "\n",
        "# Display unique value counts for specified columns\n",
        "print(\"Unique value counts in specified columns:\")\n",
        "print(unique_value_counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zB5Qf7yh5aoV",
        "outputId": "e8f2944c-a6b4-4af9-bcc9-efada640812c"
      },
      "outputs": [],
      "source": [
        "# Identify columns with NaN values\n",
        "columns_with_nan = nan_counts_specific.index.tolist()\n",
        "\n",
        "# Drop rows where any of the specified columns have NaN values\n",
        "input.dropna(subset=columns_with_nan, inplace=True)\n",
        "\n",
        "# Confirm that rows with NaN values in specified columns are dropped\n",
        "print(\"After dropping rows with NaN values:\")\n",
        "print(input.shape)  # Check the shape of the DataFrame after dropping rows\n",
        "\n",
        "columns_of_interest = input.columns  # Adjust column indices as needed\n",
        "\n",
        "nan_counts_specific = input[columns_of_interest].isna().sum()\n",
        "nan_counts_specific = nan_counts_specific[nan_counts_specific != 0]\n",
        "\n",
        "if not nan_counts_specific.empty:\n",
        "    print(\"NaN counts for specified columns:\")\n",
        "    print(nan_counts_specific)\n",
        "else:\n",
        "    print(\"No NaN values found in specified columns.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xncoaRxi5k-u",
        "outputId": "8c5870d8-f6fa-4099-a8be-473bc026c34f"
      },
      "outputs": [],
      "source": [
        "# Check the unique values in each column\n",
        "for column in input.columns[1:8]:\n",
        "    unique_values = sorted(input[column].unique())\n",
        "    print(f\"Column '{column}' has {len(unique_values)} unique values: {unique_values}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "aAclu6p17f5H"
      },
      "outputs": [],
      "source": [
        "input.drop(columns=['eeg.date'], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "t2xEF_zB6Ehd",
        "outputId": "07932283-3cf8-41f6-dd58-b839ab944f7d"
      },
      "outputs": [],
      "source": [
        "input.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9jvuThfc6VfV",
        "outputId": "8094d055-4f09-4ff6-c571-1e378bb0f4b4"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Encode categorical columns and store mappings\n",
        "label_encoders = {}\n",
        "mappings = {}\n",
        "columns=['sex','main.disorder','specific.disorder']\n",
        "for column in columns:\n",
        "    le = LabelEncoder()\n",
        "    input[column] = le.fit_transform(input[column])\n",
        "    label_encoders[column] = le\n",
        "    mappings[column] = dict(zip(le.classes_, le.transform(le.classes_)))\n",
        "\n",
        "# Check the unique values in each column and their mappings\n",
        "for column in columns:\n",
        "    unique_values = sorted(input[column].unique())\n",
        "    print(f\"Column '{column}' has {len(unique_values)} unique values: {unique_values}\")\n",
        "    print(f\"Mappings: {mappings[column]}\")\n",
        "\n",
        "# Display the encoded data\n",
        "#print(input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "HjBz69cg7WT2",
        "outputId": "7de19aad-40d1-4b47-8424-71058e6bc4b7"
      },
      "outputs": [],
      "source": [
        "input.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "hy21rHKMQTcH",
        "outputId": "09abdfc7-15d6-4459-8c27-99bc50595ab5"
      },
      "outputs": [],
      "source": [
        "input_copy=input.copy().iloc[:, np.r_[1:6]]\n",
        "\n",
        "corr_matrix = input_copy.corr()\n",
        "display(corr_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "ccAHFYznQ5H8",
        "outputId": "302cd1c3-4447-4323-dd0b-7c68f016c6d7"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 4))  # Set the size of the plot\n",
        "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0)\n",
        "plt.title('Correlation Matrix Heatmap')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "T3vJjUPLRHs5"
      },
      "outputs": [],
      "source": [
        "from statsmodels.stats.multitest import multipletests\n",
        "from scipy.stats import pearsonr\n",
        "import networkx as nx\n",
        "\n",
        "data=input_copy\n",
        "#Calculate correlation matrix and p-values\n",
        "correlations = data.corr()\n",
        "p_values = np.zeros_like(correlations)\n",
        "\n",
        "for i in range(data.shape[1]):\n",
        "    for j in range(data.shape[1]):\n",
        "        if i != j:\n",
        "            _, p_values[i, j] = pearsonr(data.iloc[:, i], data.iloc[:, j])\n",
        "\n",
        "# Apply Benjamini-Hochberg correction for multiple comparisons\n",
        "p_values_flat = p_values.flatten()\n",
        "_, corrected_p_values_flat, _, _ = multipletests(p_values_flat, method='fdr_bh')\n",
        "corrected_p_values = corrected_p_values_flat.reshape(p_values.shape)\n",
        "\n",
        "# Apply thresholds (r >= 0.25 and p < 0.05)\n",
        "significant_edges = np.where((np.abs(correlations) >= 0.15) & (corrected_p_values < 0.05), correlations, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 675
        },
        "id": "xsEIS_TNSisB",
        "outputId": "3bfd7e58-6be7-4470-fba9-e66a876f430f"
      },
      "outputs": [],
      "source": [
        "# Create an undirected graph\n",
        "G = nx.Graph()\n",
        "\n",
        "# Add nodes (symptoms)\n",
        "for col in data.columns:\n",
        "    G.add_node(col)\n",
        "\n",
        "# Add edges for significant correlations with edge weights\n",
        "for i in range(len(data.columns)):\n",
        "    for j in range(i + 1, len(data.columns)):  # Avoid duplicate edges\n",
        "        if significant_edges[i, j] != 0:\n",
        "            # Determine edge color based on the sign of correlation\n",
        "            color = 'green' if significant_edges[i, j] > 0 else 'red'\n",
        "            G.add_edge(data.columns[i], data.columns[j], weight=significant_edges[i, j], color=color)\n",
        "\n",
        "# Extract edges and colors\n",
        "edges = G.edges(data=True)\n",
        "weights = [d['weight'] for (u, v, d) in edges]\n",
        "colors = [d['color'] for (u, v, d) in edges]\n",
        "\n",
        "# Normalize weights for edge width\n",
        "norm_weights = [abs(w) for w in weights]\n",
        "\n",
        "# Position nodes with a spring layout\n",
        "pos = nx.circular_layout(G)\n",
        "\n",
        "# Plot the graph\n",
        "plt.figure(figsize=(8, 8))\n",
        "\n",
        "# Draw nodes\n",
        "nx.draw_networkx_nodes(G, pos, node_color='lightblue', node_size=700)\n",
        "\n",
        "# Draw edges with color coding based on weights\n",
        "nx.draw_networkx_edges(G, pos, edgelist=edges, edge_color=colors, width=[w*7 for w in norm_weights])\n",
        "\n",
        "# Draw labels\n",
        "nx.draw_networkx_labels(G, pos, font_size=10, font_color=\"black\")\n",
        "\n",
        "plt.title('Correlation Network with Weighted and Color-Coded Edges')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 710
        },
        "id": "_n-VVQDoSkwi",
        "outputId": "156b1387-a219-48d2-c858-552a8898b0c6"
      },
      "outputs": [],
      "source": [
        "import networkx as nx\n",
        "from networkx.algorithms.clique import find_cliques\n",
        "from networkx.algorithms.approximation import clique\n",
        "\n",
        "### Identifying Cliques\n",
        "\n",
        "# Identify all maximal cliques\n",
        "cliques = list(find_cliques(G))\n",
        "\n",
        "# Find the largest maximal clique (i.e., the maximum clique)\n",
        "maximum_clique = max(cliques, key=len)\n",
        "\n",
        "print(\"Maximal Cliques: \", cliques)\n",
        "print(\"Maximum Clique: \", maximum_clique)\n",
        "\n",
        "### Visualize Cliques\n",
        "\n",
        "# Create a new plot to visualize the cliques\n",
        "plt.figure(figsize=(8, 8))\n",
        "\n",
        "# Draw the base network again\n",
        "nx.draw_networkx_nodes(G, pos, node_color='lightblue', node_size=700)\n",
        "nx.draw_networkx_edges(G, pos, edgelist=edges, edge_color=colors, width=[w*5 for w in norm_weights])\n",
        "nx.draw_networkx_labels(G, pos, font_size=10, font_color=\"black\")\n",
        "\n",
        "# Highlight maximal cliques (all cliques) with blue edges\n",
        "for clique in cliques:\n",
        "    clique_edges = [(clique[i], clique[j]) for i in range(len(clique)) for j in range(i + 1, len(clique))]\n",
        "    nx.draw_networkx_edges(G, pos, edgelist=clique_edges, edge_color='blue', width=3, alpha=0.6)\n",
        "\n",
        "# Highlight the maximum clique with darker blue edges\n",
        "max_clique_edges = [(maximum_clique[i], maximum_clique[j]) for i in range(len(maximum_clique)) for j in range(i + 1, len(maximum_clique))]\n",
        "nx.draw_networkx_edges(G, pos, edgelist=max_clique_edges, edge_color='darkblue', width=5, alpha=1.0)\n",
        "\n",
        "plt.title('Correlation Network with Maximal and Maximum Cliques')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 859
        },
        "id": "Q60M2_j4SvCg",
        "outputId": "633d39c7-b994-41a6-bb93-2992bd3ce6f9"
      },
      "outputs": [],
      "source": [
        "from sklearn.covariance import GraphicalLassoCV\n",
        "\n",
        "# Fit a Graphical Lasso model to estimate partial correlations\n",
        "model = GraphicalLassoCV()\n",
        "model.fit(data)\n",
        "\n",
        "# Extract the partial correlation matrix\n",
        "partial_corr_matrix = -model.precision_ / np.sqrt(np.outer(np.diag(model.precision_), np.diag(model.precision_)))\n",
        "\n",
        "# Create a graph for partial correlations\n",
        "G_partial = nx.Graph()\n",
        "\n",
        "# Add nodes (variables)\n",
        "for col in data.columns:\n",
        "    G_partial.add_node(col)\n",
        "\n",
        "# Add edges (partial correlations) only if significant\n",
        "for i, col1 in enumerate(data.columns):\n",
        "    for j, col2 in enumerate(data.columns):\n",
        "        if i != j and abs(partial_corr_matrix[i, j]) >= 0.25:\n",
        "            G_partial.add_edge(col1, col2, weight=partial_corr_matrix[i, j])\n",
        "\n",
        "# Plot the partial correlation network\n",
        "plt.figure(figsize=(8, 8))\n",
        "pos = nx.circular_layout(G_partial)\n",
        "edges = G_partial.edges(data=True)\n",
        "\n",
        "nx.draw(G_partial, pos, with_labels=True, node_size=500, node_color='lightgreen', font_size=10)\n",
        "nx.draw_networkx_edges(G_partial, pos, edgelist=edges, width=[abs(d['weight'])*5 for (u, v, d) in edges])\n",
        "\n",
        "plt.title('Partial Correlation Network')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "xxTzW8Yc7wNF",
        "outputId": "181534e1-2ffe-4fe4-c0fc-e95dda6f2eb6"
      },
      "outputs": [],
      "source": [
        "# Function to create pie charts\n",
        "def create_pie_chart(ax, column_name, data, mappings):\n",
        "    counts = data[column_name].value_counts()\n",
        "    labels = [list(mappings[column_name].keys())[list(mappings[column_name].values()).index(i)] for i in counts.index]\n",
        "    ax.pie(counts, labels=labels, autopct='%1.1f%%', startangle=140, colors=plt.cm.Paired.colors)\n",
        "    ax.set_title(f'Distribution of {column_name}')\n",
        "    ax.axis('equal')\n",
        "\n",
        "#columns we want to work on\n",
        "columns_to_plot = ['sex', 'main.disorder', 'specific.disorder']\n",
        "# Number of columns for the subplot grid\n",
        "num_columns = 3\n",
        "num_plots = len(columns_to_plot)\n",
        "\n",
        "# Calculate number of rows needed\n",
        "num_rows = (num_plots + num_columns - 1) // num_columns\n",
        "\n",
        "fig, axes = plt.subplots(num_rows, num_columns, figsize=(15, num_rows * 5))\n",
        "\n",
        "# Flatten axes array if there's more than one row\n",
        "if num_rows > 1:\n",
        "    axes = axes.flatten()\n",
        "\n",
        "# Create pie charts for each categorical variable\n",
        "for i, column in enumerate(columns_to_plot):\n",
        "    create_pie_chart(axes[i], column, input, mappings)\n",
        "\n",
        "# Remove any unused subplots\n",
        "for i in range(num_plots, len(axes)):\n",
        "    fig.delaxes(axes[i])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZtqhFUgFk-n",
        "outputId": "7dc84c63-d810-47dc-dc9e-c684b89b2508"
      },
      "outputs": [],
      "source": [
        "# Decoding the columns back to original values\n",
        "decoded_data = input.copy()\n",
        "for column in columns:\n",
        "    le = label_encoders[column]\n",
        "    decoded_data[column] = input[column].map({v: k for k, v in mappings[column].items()})\n",
        "\n",
        "# Group by 'main.disorder' and list unique 'specific.disorder' for each group\n",
        "main_to_specific = decoded_data.groupby('main.disorder')['specific.disorder'].unique()\n",
        "\n",
        "# Convert the result to a dictionary for easier inspection\n",
        "main_to_specific_dict = main_to_specific.to_dict()\n",
        "\n",
        "print(main_to_specific_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EmjsbOO0PLDB",
        "outputId": "88a37795-0168-4f25-bce7-e82704a63d39"
      },
      "outputs": [],
      "source": [
        "# Create mappings from your label encoders (example mappings provided)\n",
        "mappings = {\n",
        "    'main.disorder': {\n",
        "        'Addictive disorder': 0, 'Anxiety disorder': 1, 'Healthy control': 2,\n",
        "        'Mood disorder': 3, 'Obsessive compulsive disorder': 4, 'Schizophrenia': 5,\n",
        "        'Trauma and stress related disorder': 6\n",
        "    },\n",
        "    'specific.disorder': {\n",
        "        'Acute stress disorder': 0, 'Adjustment disorder': 1, 'Alcohol use disorder': 2,\n",
        "        'Behavioral addiction disorder': 3, 'Bipolar disorder': 4, 'Depressive disorder': 5,\n",
        "        'Healthy control': 6, 'Obsessive compulsitve disorder': 7, 'Panic disorder': 8,\n",
        "        'Posttraumatic stress disorder': 9, 'Schizophrenia': 10, 'Social anxiety disorder': 11\n",
        "    }\n",
        "}\n",
        "\n",
        "# Group data by main disorder\n",
        "groups = {}\n",
        "for main_disorder, specific_disorders in main_to_specific.items():\n",
        "    group_data = input[input['main.disorder'] == mappings['main.disorder'][main_disorder]]\n",
        "    for specific_disorder in specific_disorders:\n",
        "        group_data_specific = group_data[group_data['specific.disorder'] == mappings['specific.disorder'][specific_disorder]]\n",
        "        groups[specific_disorder] = group_data_specific\n",
        "\n",
        "# Perform t-tests for continuous variables\n",
        "continuous_vars = ['age', 'education', 'IQ']\n",
        "t_test_results = {}\n",
        "\n",
        "for var in continuous_vars:\n",
        "    for specific_disorder, group_data in groups.items():\n",
        "        hc_group = groups.get('Healthy control')\n",
        "        if hc_group is not None:\n",
        "            hc_values = hc_group[var].dropna()\n",
        "            group_values = group_data[var].dropna()\n",
        "            if hc_values.empty or group_values.empty:\n",
        "                print(f\"Skipping t-test for {specific_disorder} on {var} due to insufficient data.\")\n",
        "                t_test_results[(specific_disorder, var)] = {'t_stat': np.nan, 'p_value': np.nan}\n",
        "            else:\n",
        "                t_stat, p_value = ttest_ind(group_values, hc_values)\n",
        "                t_test_results[(specific_disorder, var)] = {'t_stat': t_stat, 'p_value': p_value}\n",
        "        else:\n",
        "            print(f\"Healthy control group not found for {specific_disorder} on {var}.\")\n",
        "\n",
        "print(\"T-test Results:\")\n",
        "print(t_test_results)\n",
        "\n",
        "# Perform chi-squared tests for categorical variables\n",
        "categorical_vars = ['sex']\n",
        "chi2_results = {}\n",
        "\n",
        "for var in categorical_vars:\n",
        "    for specific_disorder, group_data in groups.items():\n",
        "        hc_group = groups.get('Healthy control')\n",
        "        if hc_group is not None:\n",
        "            contingency_table = pd.crosstab(group_data[var], hc_group[var])\n",
        "            if contingency_table.size == 0:\n",
        "                print(f\"Skipping chi-squared test for {specific_disorder} on {var} due to insufficient data.\")\n",
        "                chi2_results[(specific_disorder, var)] = {'chi2': np.nan, 'p_value': np.nan}\n",
        "            else:\n",
        "                chi2, p_value, dof, expected = chi2_contingency(contingency_table)\n",
        "                chi2_results[(specific_disorder, var)] = {'chi2': chi2, 'p_value': p_value}\n",
        "        else:\n",
        "            print(f\"Healthy control group not found for {specific_disorder} on {var}.\")\n",
        "\n",
        "print(\"Chi-squared Test Results:\")\n",
        "print(chi2_results)\n",
        "\n",
        "\n",
        "\n",
        "def chi_square_test(column1, column2, data):\n",
        "    contingency_table = pd.crosstab(data[column1], data[column2])\n",
        "    chi2, p, dof, ex = chi2_contingency(contingency_table)\n",
        "    return chi2, p\n",
        "\n",
        "chi_square_results = {}\n",
        "categorical_columns = ['main.disorder', 'specific.disorder']\n",
        "\n",
        "# Iterate through pairs of columns and their unique values\n",
        "for column2 in categorical_columns:\n",
        "    unique_values = input[column2].unique()\n",
        "    for unique_value in unique_values:\n",
        "        # Create a new binary column for the unique value\n",
        "        input[f'{column2}_{unique_value}'] = (input[column2] == unique_value).astype(int)\n",
        "\n",
        "        # Perform chi-square test between 'sex' and the new binary column\n",
        "        chi2, p_value = chi_square_test('sex', f'{column2}_{unique_value}', input)\n",
        "        chi_square_results[('sex', f'{column2}_{unique_value}')] = (chi2, p_value)\n",
        "\n",
        "# Print the chi-square statistics and p-values for each pair of variables\n",
        "for key, value in chi_square_results.items():\n",
        "    chi2, p_value = value\n",
        "\n",
        "    print(f\"Chi-square test between {key[0]} and {key[1]}: chi2 = {chi2}, p-value = {p_value}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ifBjKGEz1Ouk",
        "outputId": "5825aaf6-c041-4dfe-f1fa-62a944b306e4"
      },
      "outputs": [],
      "source": [
        "print(input.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sK6ivCXMkrNO",
        "outputId": "7e183d03-cc13-419c-fde3-6d1efe36f000"
      },
      "outputs": [],
      "source": [
        "# Assuming input is your DataFrame\n",
        "# Create mappings from your label encoders (example mappings provided)\n",
        "mappings = {\n",
        "    'main.disorder': {\n",
        "        'Addictive disorder': 0, 'Anxiety disorder': 1, 'Healthy control': 2,\n",
        "        'Mood disorder': 3, 'Obsessive compulsive disorder': 4, 'Schizophrenia': 5,\n",
        "        'Trauma and stress related disorder': 6\n",
        "    },\n",
        "    'specific.disorder': {\n",
        "        'Acute stress disorder': 0, 'Adjustment disorder': 1, 'Alcohol use disorder': 2,\n",
        "        'Behavioral addiction disorder': 3, 'Bipolar disorder': 4, 'Depressive disorder': 5,\n",
        "        'Healthy control': 6, 'Obsessive compulsitve disorder': 7, 'Panic disorder': 8,\n",
        "        'Posttraumatic stress disorder': 9, 'Schizophrenia': 10, 'Social anxiety disorder': 11\n",
        "    }\n",
        "}\n",
        "\n",
        "# Example mapping from main disorder to specific disorders\n",
        "main_to_specific = {\n",
        "    'Addictive disorder': ['Alcohol use disorder', 'Behavioral addiction disorder'],\n",
        "    'Anxiety disorder': ['Panic disorder', 'Social anxiety disorder'],\n",
        "    'Healthy control': ['Healthy control'],\n",
        "    'Mood disorder': ['Depressive disorder', 'Bipolar disorder'],\n",
        "    'Obsessive compulsive disorder': ['Obsessive compulsitve disorder'],\n",
        "    'Schizophrenia': ['Schizophrenia'],\n",
        "    'Trauma and stress related disorder': ['Acute stress disorder', 'Posttraumatic stress disorder', 'Adjustment disorder']\n",
        "}\n",
        "\n",
        "# Group data by main disorder\n",
        "groups = {}\n",
        "for main_disorder, specific_disorders in main_to_specific.items():\n",
        "    group_data = input[input['main.disorder'] == mappings['main.disorder'][main_disorder]]\n",
        "    for specific_disorder in specific_disorders:\n",
        "        group_data_specific = group_data[group_data['specific.disorder'] == mappings['specific.disorder'][specific_disorder]]\n",
        "        groups[specific_disorder] = group_data_specific\n",
        "\n",
        "# Perform t-tests for continuous variables\n",
        "continuous_vars = ['age', 'education', 'IQ']\n",
        "t_test_results = {}\n",
        "\n",
        "for var in continuous_vars:\n",
        "    for specific_disorder, group_data in groups.items():\n",
        "        hc_group = groups.get('Healthy control')\n",
        "        if hc_group is not None:\n",
        "            hc_values = hc_group[var].dropna()\n",
        "            group_values = group_data[var].dropna()\n",
        "\n",
        "            if hc_values.empty or group_values.empty:\n",
        "                print(f\"Skipping t-test for {specific_disorder} on {var} due to insufficient data.\")\n",
        "                t_test_results[(specific_disorder, var)] = {'t_stat': np.nan, 'p_value': np.nan}\n",
        "            else:\n",
        "                mean_hc = np.mean(group_values)\n",
        "                std_hc = np.std(group_values)\n",
        "                t_stat, p_value = ttest_ind(group_values, hc_values)\n",
        "                t_test_results[(specific_disorder, var)] = {'t_stat': t_stat, 'p_value': p_value, 'mean': mean_hc, 'SD': std_hc}\n",
        "        else:\n",
        "            print(f\"Healthy control group not found for {specific_disorder} on {var}.\")\n",
        "\n",
        "print(\"T-test Results:\")\n",
        "print(t_test_results)\n",
        "\n",
        "# Perform chi-squared tests for categorical variables\n",
        "categorical_vars = ['sex']\n",
        "chi2_results = {}\n",
        "\n",
        "for var in categorical_vars:\n",
        "    for specific_disorder, group_data in groups.items():\n",
        "        hc_group = groups.get('Healthy control')\n",
        "        if hc_group is not None:\n",
        "            if var in group_data.columns and var in hc_group.columns:\n",
        "                group_counts = group_data[var].value_counts()\n",
        "                hc_counts = hc_group[var].value_counts()\n",
        "                contingency_table = pd.DataFrame([group_counts, hc_counts]).fillna(0)\n",
        "                print(f\"Contingency table for {specific_disorder} on {var}:\\n{contingency_table}\")\n",
        "                if contingency_table.size == 0 or (contingency_table == 0).all().all():\n",
        "                    print(f\"Skipping chi-squared test for {specific_disorder} on {var} due to insufficient data.\")\n",
        "                    chi2_results[(specific_disorder, var)] = {'chi2': np.nan, 'p_value': np.nan}\n",
        "                else:\n",
        "                    chi2, p_value, dof, expected = chi2_contingency(contingency_table)\n",
        "                    chi2_results[(specific_disorder, var)] = {'chi2': chi2, 'p_value': p_value}\n",
        "            else:\n",
        "                print(f\"{var} not found in group data or healthy control data for {specific_disorder}.\")\n",
        "                chi2_results[(specific_disorder, var)] = {'chi2': np.nan, 'p_value': np.nan}\n",
        "        else:\n",
        "            print(f\"Healthy control group not found for {specific_disorder} on {var}.\")\n",
        "\n",
        "print(\"Chi-squared Test Results:\")\n",
        "print(chi2_results)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ez8QWhhLq0Ny",
        "outputId": "fb61ce9d-301a-4287-899b-d050020bd45c"
      },
      "outputs": [],
      "source": [
        "# Create a DataFrame to store the results\n",
        "results = []\n",
        "\n",
        "# Populate the results DataFrame\n",
        "for main_disorder, specific_disorders in main_to_specific.items():\n",
        "    for specific_disorder in specific_disorders:\n",
        "        row = {'Main/specific  ': specific_disorder}\n",
        "\n",
        "        # Age statistics\n",
        "        age_stats = t_test_results.get((specific_disorder, 'age'), {})\n",
        "        row['  Age Mean(SD)'] = f\"{age_stats.get('mean', np.nan):.2f}({age_stats.get('SD', np.nan):.2f})\"\n",
        "        row['  Age t'] = f\"{age_stats.get('t_stat', np.nan):.2f}\"\n",
        "\n",
        "        # Sex statistics\n",
        "        sex_counts = groups[specific_disorder]['sex'].value_counts(normalize=True).fillna(0) * 100\n",
        "        male_count = sex_counts.get(1, 0)\n",
        "        female_count = sex_counts.get(0, 0)\n",
        "        sex_chi2 = chi2_results.get((specific_disorder, 'sex'), {}).get('chi2', np.nan)\n",
        "        row['       Sex Counts(proportions)'] = f\"Male: {male_count:.1f}%, Female: {female_count:.1f}%\"\n",
        "        row['  Sex χ2'] = f\"{sex_chi2:.2f}\"\n",
        "\n",
        "        # Education statistics\n",
        "        education_stats = t_test_results.get((specific_disorder, 'education'), {})\n",
        "        row['  Education Mean(SD)'] = f\"{education_stats.get('mean', np.nan):.2f}({education_stats.get('SD', np.nan):.2f})\"\n",
        "        row['  Education t'] = f\"{education_stats.get('t_stat', np.nan):.2f}\"\n",
        "\n",
        "        # IQ statistics\n",
        "        iq_mean = groups[specific_disorder]['IQ'].mean()\n",
        "        row['  IQ Mean(SD)'] = f\"{iq_mean:.2f}\"\n",
        "\n",
        "        results.append(row)\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "\n",
        "# Display the results DataFrame in a single line for each row\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "pd.set_option('display.width', None)\n",
        "pd.set_option('display.max_columns', None)\n",
        "print(results_df.to_string(index=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "UVw4NfOvTl-B",
        "outputId": "c964591d-2c19-4c6c-8771-257d678be049"
      },
      "outputs": [],
      "source": [
        "input.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_CBJogNowio"
      },
      "source": [
        "### TABLE 1 | Demographic characteristics of samples(ORIGINAL PAPER)\n",
        "\n",
        "| Main/specific              | Age            | Sex                                 | Education       | IQ                |\n",
        "|----------------------------|----------------|-------------------------------------|-----------------|-------------------|\n",
        "|                            | Mean(SD)       | Counts(proportions)                 | Mean(SD)        | Mean(SD)          |\n",
        "|----------------------------|----------------|-------------------------------------|-----------------|-------------------|\n",
        "| Healthy control (n=95)     | 25.72(4.55)    | Male:60(63.2%) Female:35(36.8%)     | 14.91(2.06)     | 116.24(10.94)     |\n",
        "| Schizophrenia (n=117)      | 31.73(12.10)   | 4.58*** Male:65(55.6%) Female:52(44.4%) | 1.25 12.84(2.95) | −5.76*** 89.62(17.51) |\n",
        "| Mood disorder (n=266)      | 30.87(12.70)   | 3.86*** Male:151(56.8%) Female:115(43.2%) | 1.17 13.31(2.48) | −5.59*** 101.58(15.70) |\n",
        "| Depressive disorder (n=199)| 31.26(13.23)   | 3.96*** Male:109(54.8%) Female:90(45.2%) | 1.84 13.05(2.51) | −6.25*** 101.85(15.28) |\n",
        "| Bipolar disorder (n=67)    | 29.71(11.01)   | 3.17** Male:42(62.7%) Female:25(37.3%) | 0.00 14.11(2.21) | −2.36* 100.81(16.98) |\n",
        "| Anxiety disorder (n=107)   | 29.01(10.56)   | 2.81** Male:79(73.8%) Female:28(26.2%) | 2.67 13.14(2.42) | −5.52*** 98.31(16.31) |\n",
        "| Panic disorder (n=59)      | 31.05(11.30)   | 4.10*** Male:38(64.4%) Female:21(35.6%) | 0.25 13.45(2.91) | −3.62*** 100.31(14.77) |\n",
        "| Social anxiety disorder (n=48)| 26.51(9.09) | 0.69 Male:41(85.4%) Female:7(14.6%) | 7.61** 12.78(1.60) | −6.28*** 95.85(17.89) |\n",
        "| Obsessive–compulsive disorder (n=46)| 28.48(9.83) | 2.28* Male:38(82.6%) Female:8(17.4%) | 5.53* 13.93(2.33) | −2.45* 107.80(15.24) |\n",
        "| Addictive disorder (n=186) | 29.63(10.89)   | 3.34*** Male:164(88.2%) Female:22(11.8%) | 24.33*** 13.23(2.53) | −5.55*** 103.88(16.19) |\n",
        "| Alcohol use disorder (n=93)| 34.16(11.88)   | 6.45*** Male:75(80.6%) Female:18(19.4%) | 7.09** 13.29(3.07) | −4.22*** 103.38(13.61) |\n",
        "| Behavioral addiction disorder (n=93)| 25.09(7.48) | −0.70 Male:89(95.7%) Female:4(4.3%) | 30.26*** 13.16(1.89) | −6.02*** 104.38(18.49) |\n",
        "| Trauma and stress-related disorder (n=128)| 36.09(13.82) | 7.03*** Male:44(34.4%) Female:84(65.6%) | 18.15*** 13.57(2.45) | −4.28*** 98.89(15.86) |\n",
        "| Post-traumatic stress disorder (n=52)| 42.74(13.0) | 11.55*** Male:14(26.9%) Female:38(73.1%) | 17.65*** 13.37(2.54) | −3.95*** 98.90(15.69) |\n",
        "| Acute stress disorder (n=38)| 28.90(9.05) | 2.69** Male:3(7.9%) Female:35(92.1%) | 33.25*** 14.26(2.27) | −1.59 104.06(15.43) |\n",
        "| Adjustment disorder (n=38)| 34.19(14.90) | 5.01*** Male:27(75.0%) Female:11(25.0%) | 0.74 13.26(2.41) | −4.21*** 94.24(15.41) |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cPL-tHt10K4e",
        "outputId": "54080833-1459-4141-dd34-0dff7a02e611"
      },
      "outputs": [],
      "source": [
        "print(input.columns[8:1148])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zWuRcC5Nurgj"
      },
      "source": [
        "# **Correlation Network Analysis**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 679
        },
        "id": "WVg6dNSG4Hiz",
        "outputId": "e5d51fff-4163-4f44-d3d5-4c1d36df039c"
      },
      "outputs": [],
      "source": [
        "corr_matrix = input.iloc[:,np.r_[2:7]].corr()\n",
        "display(corr_matrix)\n",
        "plt.figure(figsize=(8, 4))  # Set the size of the plot\n",
        "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0)\n",
        "plt.title('Correlation Matrix Heatmap')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "1MtKn2D1mAt3"
      },
      "outputs": [],
      "source": [
        "from statsmodels.stats.multitest import multipletests\n",
        "from scipy.stats import pearsonr\n",
        "import networkx as nx\n",
        "\n",
        "data=input.copy()\n",
        "data = data.iloc[:, np.r_[2:6]]\n",
        "#Calculate correlation matrix and p-values\n",
        "correlations = data.corr()\n",
        "p_values = np.zeros_like(correlations)\n",
        "\n",
        "for i in range(data.shape[1]):\n",
        "    for j in range(data.shape[1]):\n",
        "        if i != j:\n",
        "            _, p_values[i, j] = pearsonr(data.iloc[:, i], data.iloc[:, j])\n",
        "\n",
        "# Apply Benjamini-Hochberg correction for multiple comparisons\n",
        "p_values_flat = p_values.flatten()\n",
        "_, corrected_p_values_flat, _, _ = multipletests(p_values_flat, method='fdr_bh')\n",
        "corrected_p_values = corrected_p_values_flat.reshape(p_values.shape)\n",
        "\n",
        "# Apply thresholds (r >= 0.15 and p < 0.05)\n",
        "significant_edges = np.where((np.abs(correlations) >= 0.15) & (corrected_p_values < 0.05), correlations, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 675
        },
        "id": "wc2B3ttiml-z",
        "outputId": "237392bf-1f24-4c90-d9e7-714675ecfcd2"
      },
      "outputs": [],
      "source": [
        "# Create an undirected graph\n",
        "G = nx.Graph()\n",
        "\n",
        "# Add nodes (symptoms)\n",
        "for col in data.columns:\n",
        "    G.add_node(col)\n",
        "\n",
        "\n",
        "# Add edges for significant correlations with edge weights\n",
        "for i in range(len(data.columns)):\n",
        "    for j in range(i + 1, len(data.columns)):  # Avoid duplicate edges\n",
        "        if significant_edges[i, j] != 0:\n",
        "            # Determine edge color based on the sign of correlation\n",
        "            color = 'green' if significant_edges[i, j] > 0 else 'red'\n",
        "            G.add_edge(data.columns[i], data.columns[j], weight=significant_edges[i, j], color=color)\n",
        "\n",
        "# Extract edges and colors\n",
        "edges = G.edges(data=True)\n",
        "weights = [d['weight'] for (u, v, d) in edges]\n",
        "colors = [d['color'] for (u, v, d) in edges]\n",
        "\n",
        "\n",
        "# Normalize weights for edge width\n",
        "norm_weights = [abs(w) for w in weights]\n",
        "\n",
        "# ciruclar layout for easy visualization\n",
        "pos = nx.circular_layout(G)\n",
        "\n",
        "# Plot the graph\n",
        "plt.figure(figsize=(8, 8))\n",
        "\n",
        "# Draw nodes\n",
        "nx.draw_networkx_nodes(G, pos, node_color='lightblue', node_size=700)\n",
        "\n",
        "# Draw edges with color coding based on weights\n",
        "nx.draw_networkx_edges(G, pos, edgelist=edges, edge_color=colors, width=[w*7 for w in norm_weights])\n",
        "\n",
        "# Draw labels\n",
        "nx.draw_networkx_labels(G, pos,font_size=10, font_color=\"black\")\n",
        "\n",
        "plt.title('Correlation Network with Weighted and Color-Coded Edges')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 807
        },
        "id": "j7ym2jQdtLXl",
        "outputId": "664bd76c-c227-439f-e381-7c16178c83d0"
      },
      "outputs": [],
      "source": [
        "# Original node names\n",
        "node_names = {\n",
        "    'age': 'Age',\n",
        "    'main.disorder': 'Main\\nDisorder',\n",
        "    'education': 'Education',\n",
        "    'IQ': 'IQ'\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "# Rename nodes in the graph\n",
        "G = nx.relabel_nodes(G, node_names)\n",
        "\n",
        "# Extract edges and colors again after renaming nodes\n",
        "edges = G.edges(data=True)\n",
        "weights = [d['weight'] for (u, v, d) in edges]\n",
        "colors = [d['color'] for (u, v, d) in edges]\n",
        "\n",
        "# Normalize weights for edge width\n",
        "norm_weights = [abs(w) for w in weights]\n",
        "\n",
        "# Circular layout for easy visualization\n",
        "pos = nx.circular_layout(G)\n",
        "\n",
        "# Plot the graph\n",
        "plt.figure(figsize=(7, 5.7))\n",
        "\n",
        "# Draw nodes\n",
        "nx.draw_networkx_nodes(G, pos, node_color='white', node_size=3100,edgecolors='black')\n",
        "\n",
        "# Draw edges with color coding based on weights\n",
        "nx.draw_networkx_edges(G, pos, edgelist=edges, edge_color=colors, width=[w*10 for w in norm_weights])\n",
        "\n",
        "# Draw labels\n",
        "nx.draw_networkx_labels(G, pos, font_size=10, font_color=\"black\")\n",
        "\n",
        "plt.axis('off')\n",
        "\n",
        "#Save the figure\n",
        "plt.savefig('content/Correlation Network with Weighted and Color-Coded Edges-3.png', dpi=500, bbox_inches='tight')\n",
        "plt.savefig('content/Correlation Network with Weighted and Color-Coded Edges-3.pdf', dpi=500, bbox_inches='tight')\n",
        "# Show the plot\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q05Zd_8wmwdb",
        "outputId": "e4b9c922-7614-4c65-af2a-7351f578995e"
      },
      "outputs": [],
      "source": [
        "# Identify all maximal cliques\n",
        "cliques = list(find_cliques(G))\n",
        "\n",
        "# Find the largest maximal clique (i.e., the maximum clique)\n",
        "maximum_clique = max(cliques, key=len)\n",
        "\n",
        "print(\"Maximal Cliques: \", cliques)\n",
        "print(\"Maximum Clique: \", maximum_clique)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9QheQ6wvuYNj",
        "outputId": "6b0b4ef6-b8e1-491d-9e01-442416b94278"
      },
      "outputs": [],
      "source": [
        "# Calculate correlation matrix\n",
        "correlations = data.corr()\n",
        "\n",
        "# Calculate p-values for each correlation\n",
        "p_values = np.zeros_like(correlations)\n",
        "for i in range(data.shape[1]):\n",
        "    for j in range(data.shape[1]):\n",
        "        if i != j:\n",
        "            _, p_values[i, j] = pearsonr(data.iloc[:, i], data.iloc[:, j])\n",
        "\n",
        "# Apply Benjamini-Hochberg correction\n",
        "p_values_flat = p_values.flatten()\n",
        "_, corrected_p_values_flat, _, _ = multipletests(p_values_flat, method='fdr_bh')\n",
        "corrected_p_values = corrected_p_values_flat.reshape(p_values.shape)\n",
        "\n",
        "# Create a matrix for storing the correlation coefficients and significance asterisks\n",
        "formatted_matrix = pd.DataFrame(index=correlations.index, columns=correlations.columns)\n",
        "\n",
        "# Apply thresholds and add stars based on significance levels\n",
        "for i in range(data.shape[1]):\n",
        "    for j in range(i + 1):\n",
        "        corr_value = correlations.iloc[i, j]\n",
        "        if corrected_p_values[i, j] < 0.001:\n",
        "            star = '***'\n",
        "        elif corrected_p_values[i, j] < 0.01:\n",
        "            star = '**'\n",
        "        elif corrected_p_values[i, j] < 0.05:\n",
        "            star = '*'\n",
        "        else:\n",
        "            star = ''\n",
        "        formatted_matrix.iloc[i, j] = f\"{corr_value:.2f}{star}\"\n",
        "        formatted_matrix.iloc[j, i] = ''  # Set upper triangle to empty\n",
        "\n",
        "# Convert the formatted matrix to a LaTeX table format\n",
        "latex_table = formatted_matrix.to_latex()\n",
        "\n",
        "# Display the formatted correlation matrix\n",
        "print(\"Formatted Correlation Matrix:\\n\")\n",
        "print(formatted_matrix)\n",
        "\n",
        "# Display the LaTeX table\n",
        "print(\"\\nLaTeX Table:\\n\")\n",
        "print(latex_table)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "4LkPqC98ktBx"
      },
      "outputs": [],
      "source": [
        "# import networkx as nx\n",
        "# import matplotlib.pyplot as plt\n",
        "# from scipy.stats import pearsonr\n",
        "# from statsmodels.stats.multitest import multipletests\n",
        "# import numpy as np\n",
        "\n",
        "# # Define thresholds\n",
        "# r_threshold = 0.15\n",
        "# p_threshold = 0.08\n",
        "\n",
        "# # Define disorder mappings\n",
        "# disorder_mappings = {\n",
        "#     'Addictive disorder': 0,\n",
        "#     'Anxiety disorder': 1,\n",
        "#     'Healthy control': 2,\n",
        "#     'Mood disorder': 3,\n",
        "#     'Obsessive compulsive disorder': 4,\n",
        "#     'Schizophrenia': 5,\n",
        "#     'Trauma and stress related disorder': 6\n",
        "# }\n",
        "\n",
        "# # Loop through each disorder and calculate the correlation network\n",
        "# for disorder_name, disorder_code in disorder_mappings.items():\n",
        "#     # Filter the dataset for the current disorder\n",
        "#     filtered_data = input_copy[input_copy['main.disorder'] == disorder_code]\n",
        "#     filtered_data = filtered_data.drop(columns=['main.disorder'])\n",
        "\n",
        "#     # Calculate the correlation matrix and p-values\n",
        "#     correlations = filtered_data.corr()\n",
        "#     p_values = np.zeros_like(correlations)\n",
        "\n",
        "#     for i in range(filtered_data.shape[1]):\n",
        "#         for j in range(filtered_data.shape[1]):\n",
        "#             if i != j:\n",
        "#                 _, p_values[i, j] = pearsonr(filtered_data.iloc[:, i], filtered_data.iloc[:, j])\n",
        "\n",
        "#     # Apply Benjamini-Hochberg correction\n",
        "#     p_values_flat = p_values.flatten()\n",
        "#     _, corrected_p_values_flat, _, _ = multipletests(p_values_flat, method='fdr_bh')\n",
        "#     corrected_p_values = corrected_p_values_flat.reshape(p_values.shape)\n",
        "\n",
        "#     # Threshold for significant correlations\n",
        "#     significant_edges = np.where((np.abs(correlations) >= r_threshold) & (corrected_p_values < p_threshold), correlations, 0)\n",
        "\n",
        "#     # Build the network\n",
        "#     G = nx.Graph()\n",
        "#     for i in range(significant_edges.shape[0]):\n",
        "#         for j in range(i+1, significant_edges.shape[1]):\n",
        "#             if significant_edges[i, j] != 0:\n",
        "#                 G.add_edge(filtered_data.columns[i], filtered_data.columns[j], weight=significant_edges[i, j])\n",
        "\n",
        "#     # Identify cliques\n",
        "#     cliques = list(nx.find_cliques(G))\n",
        "#     maximum_clique = max(cliques, key=len)\n",
        "\n",
        "#     # Visualize the network\n",
        "#     plt.figure(figsize=(8, 8))\n",
        "#     pos = nx.circular_layout(G)\n",
        "#     edges = G.edges(data=True)\n",
        "#     weights = [d['weight'] for (u, v, d) in edges]\n",
        "#     norm_weights = [abs(w) for w in weights]\n",
        "\n",
        "#     nx.draw_networkx_nodes(G, pos, node_color='lightblue', node_size=700)\n",
        "#     nx.draw_networkx_edges(G, pos, edgelist=edges, width=[w*7 for w in norm_weights])\n",
        "#     nx.draw_networkx_labels(G, pos, font_size=10, font_color=\"black\")\n",
        "\n",
        "#     plt.title(f'Correlation Network for {disorder_name}')\n",
        "#     plt.axis('off')\n",
        "#     plt.show()\n",
        "\n",
        "#     print(f\"Maximal Cliques for {disorder_name}: \", cliques)\n",
        "#     print(f\"Maximum Clique for {disorder_name}: \", maximum_clique)\n",
        "#     print(\"\\n\" + \"=\"*50 + \"\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AG7rLxkFuiA4"
      },
      "source": [
        "# **EEG Related Analysis**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 599
        },
        "id": "BM5ypzHa5KS1",
        "outputId": "5c650b70-453a-4026-d552-1bed0c84140e"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Select EEG features\n",
        "eeg_features = input.columns[7:1148]  # Assuming EEG features start from the 11th column\n",
        "scaler = StandardScaler()\n",
        "#eeg_features = input[eeg_features].select_dtypes(include=[float, int]).columns\n",
        "scaled_data = scaler.fit_transform(input[eeg_features])\n",
        "\n",
        "# Perform PCA\n",
        "pca = PCA(n_components=10)\n",
        "principal_components = pca.fit_transform(scaled_data)\n",
        "\n",
        "# Create a DataFrame with principal components\n",
        "pca_df = pd.DataFrame(data=principal_components, columns=[f'PC{i+1}' for i in range(10)])\n",
        "pca_df['Main Disorder'] = input['main.disorder']\n",
        "print(pca.explained_variance_ratio_)\n",
        "\n",
        "# Plot the principal components\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(x='PC1', y='PC2', hue='Main Disorder', data=pca_df, palette='viridis')\n",
        "plt.title('PCA of EEG Data')\n",
        "plt.xlabel('Principal Component 1')\n",
        "plt.ylabel('Principal Component 2')\n",
        "plt.legend(title='Main Disorder')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 981
        },
        "id": "CquGIuaM-hrx",
        "outputId": "bbb80a2e-1d8a-46e1-fe1d-4052aa2394a2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from scipy.signal import welch\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define a function to calculate PSD\n",
        "def calculate_psd(data, fs=250):\n",
        "    freqs, psd = welch(data, fs=fs, nperseg=1024)\n",
        "    return freqs, psd\n",
        "\n",
        "# Plot PSD for different disorders\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "for disorder in input['main.disorder'].unique():\n",
        "    disorder_indices = input['main.disorder'] == disorder\n",
        "    disorder_data = input.loc[disorder_indices, input.columns[7:1148]].values.T  # Transpose for channel-wise PSD\n",
        "\n",
        "    # Calculate average PSD across all channels for this disorder\n",
        "    psd_list = []\n",
        "    for channel_data in disorder_data:\n",
        "        freqs, psd = calculate_psd(channel_data)\n",
        "        psd_list.append(psd)\n",
        "\n",
        "    mean_psd = np.mean(psd_list, axis=0)\n",
        "    plt.plot(freqs, mean_psd, label=disorder)\n",
        "\n",
        "plt.xlabel('Frequency (Hz)')\n",
        "plt.ylabel('Power Spectral Density')\n",
        "plt.title('PSD of EEG Data for Different Disorders')\n",
        "plt.legend(title='Main Disorder')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lHh_YJUa_tkg",
        "outputId": "9819caed-70ff-4011-8443-3f3accee2fe1"
      },
      "outputs": [],
      "source": [
        "# Function to perform PCA and create a DataFrame with principal components\n",
        "def perform_pca(data, n_components=2):\n",
        "    scaler = StandardScaler()\n",
        "    scaled_data = scaler.fit_transform(data)\n",
        "    pca = PCA(n_components=n_components)\n",
        "    principal_components = pca.fit_transform(scaled_data)\n",
        "    return pd.DataFrame(data=principal_components, columns=[f'PC{i+1}' for i in range(n_components)])\n",
        "\n",
        "# Group data by a demographic factor, e.g., gender\n",
        "for gender in input['sex'].unique():\n",
        "    gender_data = input[input['sex'] == gender]\n",
        "    gender_eeg_data = gender_data.iloc[:, 7:1148].values\n",
        "\n",
        "    # Perform PCA on the subgroup\n",
        "    pca_df = perform_pca(gender_eeg_data)\n",
        "    pca_df['Main_Disorder'] = gender_data['main.disorder'].values  # Ensure this is added correctly\n",
        "    pca_df['sex'] = gender  # Add the sex information to the DataFrame\n",
        "\n",
        "    # Plot PCA for the subgroup\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.scatterplot(x='PC1', y='PC2', hue='Main_Disorder', data=pca_df, palette='viridis')\n",
        "    plt.title(f'PCA of EEG Data for Gender {gender}')\n",
        "    plt.xlabel('Principal Component 1')\n",
        "    plt.ylabel('Principal Component 2')\n",
        "    plt.legend(title='Main Disorder')\n",
        "    plt.show()\n",
        "\n",
        "# Combine all PCA results for the box plot\n",
        "combined_pca_df = pd.concat([perform_pca(input[input['sex'] == gender].iloc[:, 7:1148].values).assign(Main_Disorder=input[input['sex'] == gender]['main.disorder'].values, sex=gender) for gender in input['sex'].unique()])\n",
        "\n",
        "# Box plot to compare EEG feature (e.g., a specific principal component) across subgroups\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.boxplot(x='Main_Disorder', y='PC1', hue='sex', data=combined_pca_df)\n",
        "plt.title('Comparison of PC1 across Disorders and Gender')\n",
        "plt.xlabel('Main Disorder')\n",
        "plt.ylabel('Principal Component 1')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "i2Xl_cAiG9Y_",
        "outputId": "d90badf9-5022-4ac1-b5a5-3bc50d049dbb"
      },
      "outputs": [],
      "source": [
        "plt.rc('font', family='serif', size=11)\n",
        "# Assuming df is your DataFrame containing the dataset\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.boxplot(x='main.disorder', y='age', data=input)\n",
        "plt.title('Age Distribution Across Different Disorders')\n",
        "plt.xticks(rotation=90)\n",
        "plt.savefig('content/Age Distribution Across Different Disorders.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.boxplot(x='main.disorder', y='education', data=input)\n",
        "plt.title('Education Level Distribution Across Different Disorders')\n",
        "plt.xticks(rotation=90)\n",
        "plt.savefig('content/Education Level Distribution Across Different Disorders.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.boxplot(x='main.disorder', y='IQ', data=input)\n",
        "plt.title('IQ Distribution Across Different Disorders')\n",
        "plt.xticks(rotation=90)\n",
        "plt.savefig('content/IQ Distribution Across Disorders.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bJWeCxPtHPwf",
        "outputId": "6589873e-e575-497b-e23d-519c20ff973e"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 6))\n",
        "sns.violinplot(x='main.disorder', y='age', data=input)\n",
        "plt.title('Age Distribution Across Different Disorders (Violin Plot)')\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.violinplot(x='main.disorder', y='education', data=input)\n",
        "plt.title('Education Level Distribution Across Different Disorders (Violin Plot)')\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.violinplot(x='main.disorder', y='IQ', data=input)\n",
        "plt.title('IQ Distribution Across Different Disorders (Violin Plot)')\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        },
        "id": "khbHegR3HVwx",
        "outputId": "aa971eea-02df-47d8-e185-9b6935e58ece"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load your data (assuming 'input' is your DataFrame)\n",
        "# input = pd.read_csv('your_data.csv')\n",
        "\n",
        "# Extract features and target\n",
        "# Assuming 'main.disorder' is the target variable and we are predicting a specific disorder, say 'Schizophrenia' (encoded as 5)\n",
        "target_disorder = 10\n",
        "input['target'] = (input['specific.disorder'] == target_disorder).astype(int)\n",
        "\n",
        "# Select demographic and EEG features\n",
        "demographic_features = ['age', 'education', 'IQ', 'sex']  # Add more demographic features if available\n",
        "eeg_features = input.columns[7:1148]  # Assuming EEG features start from the 8th column\n",
        "\n",
        "# Combine features\n",
        "features = demographic_features + list(eeg_features)\n",
        "X = input[features]\n",
        "y = input['target']\n",
        "\n",
        "# Standardize the data\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train logistic regression model\n",
        "model = LogisticRegression(max_iter=10000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict probabilities on the test set\n",
        "y_probs = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Calculate ROC curve and AUC\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_probs)\n",
        "auc = roc_auc_score(y_test, y_probs)\n",
        "\n",
        "# Plot ROC curve\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(fpr, tpr, color='blue', label=f'ROC curve (AUC = {auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "# Print the AUC value\n",
        "print(f'AUC: {auc:.2f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yzIxyFCmV9Mv",
        "outputId": "09f0af1c-c671-4b06-eab6-bcf70ac59402"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define the parameter grid\n",
        "param_grid = {\n",
        "    'C': [0.01, 0.1, 1, 10, 100],\n",
        "    'penalty': ['l1', 'l2'],\n",
        "    'solver': ['liblinear']\n",
        "}\n",
        "\n",
        "# Initialize GridSearchCV\n",
        "grid_search = GridSearchCV(LogisticRegression(max_iter=10000), param_grid, cv=5, scoring='roc_auc')\n",
        "\n",
        "# Fit GridSearchCV\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best parameters and best score\n",
        "best_params = grid_search.best_params_\n",
        "best_auc = grid_search.best_score_\n",
        "\n",
        "print(f'Best Parameters: {best_params}')\n",
        "print(f'Best AUC: {best_auc:.2f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        },
        "id": "In2cLOJuWbHm",
        "outputId": "07ba6ac1-6e57-48c1-c711-6fa4f480650f"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Initialize Random Forest model\n",
        "rf_model = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Fit the model\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict probabilities\n",
        "y_rf_probs = rf_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Calculate ROC curve and AUC\n",
        "rf_fpr, rf_tpr, rf_thresholds = roc_curve(y_test, y_rf_probs)\n",
        "rf_auc = roc_auc_score(y_test, y_rf_probs)\n",
        "\n",
        "# Plot ROC curve\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(rf_fpr, rf_tpr, color='blue', label=f'Random Forest ROC curve (AUC = {rf_auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "# Print the AUC value\n",
        "print(f'Random Forest AUC: {rf_auc:.2f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 599
        },
        "id": "MFAcrfo-YNaQ",
        "outputId": "718c12e3-d468-4f9a-abc0-849ba3e243b1"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "target_disorder = 5\n",
        "input['target'] = (input['main.disorder'] == target_disorder).astype(int)\n",
        "\n",
        "# Assuming 'input' is your DataFrame\n",
        "# Demographic features\n",
        "demographic_features = ['age', 'sex', 'education', 'IQ']\n",
        "\n",
        "# EEG features\n",
        "eeg_features = input.columns[20:1148]  # Adjust based on your column indices\n",
        "\n",
        "# Select features\n",
        "features = demographic_features + list(eeg_features)\n",
        "x=input[features]\n",
        "y = input['main.disorder']\n",
        "\n",
        "# Split data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "# Logistic Regression\n",
        "logreg = LogisticRegression(max_iter=10000)\n",
        "logreg.fit(X_train, y_train)\n",
        "y_logreg_probs = logreg.predict_proba(X_test)\n",
        "\n",
        "# Random Forest\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "y_rf_probs = rf.predict_proba(X_test)\n",
        "\n",
        "# Calculate ROC AUC for Logistic Regression using 'ovr' strategy\n",
        "logreg_auc = roc_auc_score(y_test, y_logreg_probs, multi_class='ovr')\n",
        "print(f'Logistic Regression AUC: {logreg_auc:.2f}')\n",
        "\n",
        "# Calculate ROC AUC for Random Forest using 'ovr' strategy\n",
        "rf_auc = roc_auc_score(y_test, y_rf_probs, multi_class='ovr')\n",
        "print(f'Random Forest AUC: {rf_auc:.2f}')\n",
        "\n",
        "# Compute ROC curve for each class and plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Logistic Regression ROC curves\n",
        "for i in range(len(logreg.classes_)):\n",
        "    # Handle cases where predictions are 1D (single probability)\n",
        "    if y_logreg_probs[:, i].ndim == 1:\n",
        "        fpr, tpr, _ = roc_curve(y_test, y_logreg_probs[:, i], pos_label=logreg.classes_[i])\n",
        "    else:\n",
        "        fpr, tpr, _ = roc_curve(y_test, y_logreg_probs[:, i][:, 1], pos_label=logreg.classes_[i])  # Access second column if 2D\n",
        "\n",
        "    #plt.plot(fpr, tpr, label=f'Logistic Regression class {logreg.classes_[i]} (AUC = {roc_auc_score(y_test, y_logreg_probs[:, i], multi_class=\"ovr\"):.2f})')\n",
        "\n",
        "\n",
        "# Random Forest ROC curves\n",
        "for i in range(len(rf.classes_)):\n",
        "    fpr, tpr, _ = roc_curve(y_test, y_rf_probs[:, i], pos_label=rf.classes_[i])\n",
        "    #plt.plot(fpr, tpr, label=f'Random Forest class {rf.classes_[i]} (AUC = {roc_auc_score(y_test, y_rf_probs[:, i], multi_class=\"ovr\"):.2f})')\n",
        "\n",
        "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OrAVYFb-bgIO",
        "outputId": "43427a27-aa4a-42b9-f36c-bbc19580584f"
      },
      "outputs": [],
      "source": [
        "# Assuming `data` is your DataFrame\n",
        "descriptive_stats = input.groupby('main.disorder')[['age', 'education', 'IQ', 'sex']].describe()\n",
        "print(descriptive_stats)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I7JwhYYyb7A4",
        "outputId": "054339b3-baad-46b6-d296-513a16bdee61"
      },
      "outputs": [],
      "source": [
        "import statsmodels.api as sm\n",
        "from statsmodels.formula.api import ols\n",
        "\n",
        "# ANOVA for sex\n",
        "model_IQ = ols('sex ~ C(Q(\"main.disorder\"))', data=input).fit()\n",
        "anova_table_IQ = sm.stats.anova_lm(model_IQ, typ=2)\n",
        "print(\"ANOVA for sex:\\n\", anova_table_IQ)\n",
        "\n",
        "# ANOVA for age\n",
        "model_age = ols('age ~ C(Q(\"main.disorder\"))', data=input).fit()\n",
        "anova_table_age = sm.stats.anova_lm(model_age, typ=2)\n",
        "print(\"ANOVA for Age:\\n\", anova_table_age)\n",
        "\n",
        "# ANOVA for education\n",
        "model_education = ols('education ~ C(Q(\"main.disorder\"))', data=input).fit()\n",
        "anova_table_education = sm.stats.anova_lm(model_education, typ=2)\n",
        "print(\"ANOVA for Education:\\n\", anova_table_education)\n",
        "\n",
        "# ANOVA for IQ\n",
        "model_IQ = ols('IQ ~ C(Q(\"main.disorder\"))', data=input).fit()\n",
        "anova_table_IQ = sm.stats.anova_lm(model_IQ, typ=2)\n",
        "print(\"ANOVA for IQ:\\n\", anova_table_IQ)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UhUMA96_f40p",
        "outputId": "3d7e1bbe-c9d5-4d39-8984-fa174d7f2567"
      },
      "outputs": [],
      "source": [
        "# Correlation matrix\n",
        "correlation_matrix = input[['age', 'education', 'IQ']].corr()\n",
        "print(\"Correlation Matrix:\\n\", correlation_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "x4nkPhX6gDkk",
        "outputId": "efb13adb-b068-4b07-c966-95089189994e"
      },
      "outputs": [],
      "source": [
        "# Example: Creating a stacked bar plot using pandas\n",
        "plt.style.use('default')  # Reset style to default\n",
        "plt.rc('font', family='serif', size=16)\n",
        "\n",
        "# Boxplot for age\n",
        "plt.figure(figsize=(10, 4))\n",
        "sns.boxplot(x='main.disorder', y='age', data=input)\n",
        "plt.xlabel('Psychiatric Disorder',fontsize=20)\n",
        "plt.ylabel('Age',fontsize=20)\n",
        "\n",
        "# Add a grid with light dotted lines\n",
        "plt.grid(True, linestyle=':', linewidth=0.75, color='black')\n",
        "#plt.title('Age Distribution Across Disorders')\n",
        "plt.setp(plt.gca().get_xticklabels(), fontsize=14, fontfamily='serif')\n",
        "plt.setp(plt.gca().get_yticklabels(), fontsize=14, fontfamily='serif')\n",
        "#plt.xticks(rotation=45, ha='right')\n",
        "plt.xticks(ticks=[0, 1, 2, 3, 4, 5, 6], labels=['AddiD', 'AnxD', 'HC', 'MD', 'OCD', 'S', 'TSD'])\n",
        "# Adjust layout to fit everything nicely\n",
        "plt.tight_layout()\n",
        "plt.savefig('content/Age Distribution Across Disorders.pdf', dpi=600, bbox_inches='tight')\n",
        "plt.savefig('content/Age Distribution Across Disorders.png', dpi=600, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "# Boxplot for education\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.boxplot(x='main.disorder', y='education', data=input)\n",
        "plt.title('Education Distribution Across Disorders')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()\n",
        "\n",
        "# Boxplot for IQ\n",
        "plt.figure(figsize=(10, 4))\n",
        "sns.boxplot(x='main.disorder', y='IQ', data=input)\n",
        "plt.xlabel('Psychiatric Disorder',fontsize=20)\n",
        "plt.ylabel('IQ',fontsize=20)\n",
        "#plt.title('IQ Distribution Across Disorders')\n",
        "# Add a grid with light dotted lines\n",
        "plt.grid(True, linestyle=':', linewidth=0.75, color='black')\n",
        "plt.setp(plt.gca().get_xticklabels(), fontsize=14, fontfamily='serif')\n",
        "plt.setp(plt.gca().get_yticklabels(), fontsize=14, fontfamily='serif')\n",
        "#plt.xticks(rotation=45, ha='right')\n",
        "plt.xticks(ticks=[0, 1, 2, 3, 4, 5, 6], labels=['AddiD', 'AnxD', 'HC', 'MD', 'OCD', 'S', 'TSD'])\n",
        "plt.tight_layout()\n",
        "plt.savefig('content/IQ Distribution Across Disorders.pdf', dpi=600, bbox_inches='tight')\n",
        "plt.savefig('content/IQ Distribution Across Disorders.png', dpi=600, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "# Bar chart for sex\n",
        "plt.figure(figsize=(10, 4))\n",
        "sns.countplot(x='main.disorder', hue='sex', data=input)\n",
        "plt.xlabel('Psychiatric Disorder', fontsize=20)\n",
        "plt.ylabel('Count', fontsize=20)\n",
        "plt.setp(plt.gca().get_xticklabels(), fontsize=14, fontfamily='serif')\n",
        "plt.setp(plt.gca().get_yticklabels(), fontsize=14, fontfamily='serif')\n",
        "legend = plt.legend(fontsize=17)\n",
        "legend.get_texts()[0].set_text('Female')\n",
        "legend.get_texts()[1].set_text('Male')\n",
        "plt.xticks(ticks=[0, 1, 2, 3, 4, 5, 6], labels=['AddiD', 'AnxD', 'HC', 'MD', 'OCD', 'S', 'TSD'])\n",
        "plt.tight_layout()\n",
        "plt.savefig('content/Sex Distribution Across Disorder.pdf', dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 579
        },
        "id": "eHxvrUqOZcAt",
        "outputId": "74af9f22-811b-4120-a15a-9413a3fb97cd"
      },
      "outputs": [],
      "source": [
        "# Calculate percentages\n",
        "data=input\n",
        "data['percentage'] = data.groupby('main.disorder')['sex'].transform(lambda x: 100 * x.count() / len(data))\n",
        "\n",
        "# Plot percentage bar chart\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(x='main.disorder', y='percentage', hue='sex', data=data, estimator=lambda x: len(x) / len(data) * 100)\n",
        "plt.title('Sex Distribution Across Disorders (Percentage)')\n",
        "plt.xticks(rotation=45)\n",
        "plt.ylabel('Percentage')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWPwaJiIgaKD",
        "outputId": "5eab70db-ccc3-4d33-e44d-a1bca0c64527"
      },
      "outputs": [],
      "source": [
        "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
        "\n",
        "# Post-hoc test for sex\n",
        "tukey_age = pairwise_tukeyhsd(endog=input['sex'], groups=input['main.disorder'], alpha=0.05)\n",
        "print(\"Tukey HSD for Sex:\\n\", tukey_age)\n",
        "\n",
        "\n",
        "# Post-hoc test for age\n",
        "tukey_age = pairwise_tukeyhsd(endog=input['age'], groups=input['main.disorder'], alpha=0.05)\n",
        "print(\"Tukey HSD for Age:\\n\", tukey_age)\n",
        "\n",
        "# Post-hoc test for education\n",
        "tukey_education = pairwise_tukeyhsd(endog=input['education'], groups=input['main.disorder'], alpha=0.05)\n",
        "print(\"Tukey HSD for Education:\\n\", tukey_education)\n",
        "\n",
        "# Post-hoc test for IQ\n",
        "tukey_IQ = pairwise_tukeyhsd(endog=input['IQ'], groups=input['main.disorder'], alpha=0.05)\n",
        "print(\"Tukey HSD for IQ:\\n\", tukey_IQ)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
